---
title: 初学爬虫
date: 2016-05-13 17:40:00
tags:
- 爬虫

---

### 工作原理
爬虫，就是伪造一个用户身份，通过URL去访问某个网页，将这个网页上的某些感兴趣的内容，利用正则式的方式提取出来。对于google，baidu的搜索部门，爬虫可以说是核心技术之一。

### python spider
python为实现基本的爬虫，提供了十分方便的模块。通常利用urllib来实现简单的爬虫。首先确定访问的url，然后对这个url生成一个request。request并不仅仅是一个简单的访问请求，它可以采用post，get等方式，来实现数据的提交。

	request = urllib2.Request(url, data, headers)
	response = urllib2.urlopen(request)
	print response.read()
	
post和get的一个差别在于，get的方式是直接以链接形式访问，链接中包含了所有参数。这里简单写一下爬虫中，post和get的使用。

	values = {"username": "user", "password": "pass"}
	#post
	data = urlencode(values)
	request = urllib2.Request(url, data)
	#get
	url = url + "?" + data
	request = urllib2.Request(url)

某些情况下，需要设置访问的headers，才能对网页进行正常的访问。例如防盗链，服务器有时候会检查headers的referer是不是自己。headers是放在request之中的。除了在初始化的时候赋值，还可以添加headers。

	＃设置headers
	headers = { 'User-Agent' : 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)','Referer':'http://www.zhihu.com/articles' }  
	request = urllib2.Request(url, data, headers)
	request.add_header('cache-control', 'no-cache')
	
### 正则表达式
正则表达式是用来提取网页中感兴趣部分的工具。当然，首先自己要对网页源代码有所了解才行。这里列出一个python正则式的匹配规则图。